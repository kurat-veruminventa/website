---
template: SinglePost
title: A Smart, Personalized Interaction System
status: Published
date: '2019-10-11'
author: 'Haakon Fuhre Pettersen'
authorlink: /team/haakon/
role: 'Chief Technology Officer'
portrait: 'https://ntention.com/images/about/Haakon.jpg'
email: mailto:hfp@ntention.com
linkedin: https://www.linkedin.com/in/haakon-fuhre-pettersen/
featuredImage: 'https://ntention.com/images/posts/Default.jpg'
postType: /research
categories:
    - category: Research
    - category: Interaction
excerpt: >-
  Every person is different. Our background and our previous experiences with technology shape the way we interact with both software and hardware. What one person finds intuitive, may not be intuitive for someone else.
meta:
  description: Every person is different. Our background and our previous experiences with technology shape the way we interact with both software and hardware. What one person finds intuitive, may not be intuitive for someone else. Thus, it is critical for the interaction system of the future
  title: A Smart, Personalized Interaction System - Ntention
  absoluteImageUrl: 'https://ntention.com/images/posts/Default.jpg'
  type: article
---
####Distinguish the intent of each individual user
Every person is different. Our background and our previous experiences with technology shape the way we interact with both software and hardware. What one person finds intuitive, may not be intuitive for someone else. Thus, it is critical for the interaction system of the future to be able to distinguish the intent of each individual user and be able to translate this to the intended command or set of commands.

Today, Ntention can create personalized interaction systems by recording a set of gestures. These will be recognized while using the ‘Gesture Recognition’ software in any application, and they are directly mapped to certain functionality. This means each user is able to create their own personalized interaction system, using gestures they find natural and intuitive.

Soon, Ntention can use ‘Mixed Input Methods’ combined with ‘Contextual Information’, for a fully flexible interaction system able to understand the intent of each user without having a predefined set of gestures. This will allow anyone to intuitively interact with machines and software using their inherent intuition in our ‘Plug & Play’ software solution.
